# 开发路线图 (Development Roadmap)

本文档详细规划了 BurpAI Agent 的分阶段开发计划，包括各阶段的目标、任务清单和验收标准。

## 阶段概览

| 阶段 | 名称 | 预计周期 | 主要目标 |
|------|------|---------|---------|
| Phase 1 | MVP | 2-3 周 | 基础框架 + 单轮对话 |
| Phase 2 | Agent Alpha | 3-4 周 | ReAct 循环 + 自动化测试 |
| Phase 3 | Scope & Polish | 2-3 周 | 过滤逻辑 + 被动扫描 |
| Phase 4 | Beta Release | 1-2 周 | 测试 + 优化 + 文档 |

---

## Phase 1: MVP (最小可行产品)

### 目标
建立插件基础框架，实现配置管理和单次 AI 分析功能（不包含自动发包）。

### 任务清单

#### 1.1 项目初始化
- [ ] 创建 Burp 扩展项目结构
- [ ] 配置 Gradle/Maven 构建脚本
- [ ] 集成 Burp Extender API
- [ ] 设置开发环境和调试配置

**验收标准**: 插件能在 Burp Suite 中成功加载并显示在 Extensions 列表中。

#### 1.2 配置界面 (简化版)
- [ ] 创建 Configuration Tab
- [ ] 实现 AI 引擎设置面板
  - [ ] Provider 下拉框 (OpenAI, Anthropic, Local)
  - [ ] API Key 输入框 (掩码显示)
  - [ ] Model Name 输入框
  - [ ] Base URL 输入框
  - [ ] "测试连接" 按钮
- [ ] 实现配置保存/加载功能

**验收标准**: 
- 用户可以输入并保存 API 配置
- 点击"测试连接"能验证 API Key 有效性
- 配置在 Burp 重启后能正确加载

#### 1.3 LLM Adapter (基础实现)
- [ ] 定义 `LLMAdapter` 接口
- [ ] 实现 `OpenAIAdapter` 
  - [ ] 支持 GPT-4/GPT-3.5
  - [ ] 处理 API 认证
  - [ ] 基础错误处理
- [ ] 实现 `AnthropicAdapter` (可选)
- [ ] 实现统一的消息格式转换

**验收标准**: 能够成功调用 OpenAI API 并获得响应。

#### 1.4 Repeater 右键菜单集成
- [ ] 注册 `IContextMenuFactory`
- [ ] 创建右键菜单项
  - [ ] "BurpAI Agent > Auto Analysis"
  - [ ] "BurpAI Agent > SQL Injection Only"
  - [ ] "BurpAI Agent > Custom Prompt"
- [ ] 捕获当前选中的 HTTP 请求

**验收标准**: 在 Repeater 中右键点击请求，能看到 BurpAI Agent 菜单。

#### 1.5 单轮分析功能
- [ ] 构建 System Prompt 模板
- [ ] 将 HTTP 请求转换为文本格式
- [ ] 调用 LLM 进行分析
- [ ] 解析 LLM 返回的 JSON
- [ ] 在弹窗或 Dashboard 中显示结果

**验收标准**: 
- 点击右键菜单后，能看到 AI 的分析结果
- 结果包含 `thought` 和初步判断

#### 1.6 基础 UI 展示
- [ ] 创建 Dashboard Tab
- [ ] 实现简单的任务列表视图
- [ ] 显示任务状态 (Running/Finished)
- [ ] 显示 AI 的分析结果

**验收标准**: Dashboard 能显示分析历史和结果。

### Phase 1 里程碑
- 用户能在 Repeater 中触发 AI 分析
- AI 能返回对请求的初步判断（如"可能存在 SQL 注入"）
- 配置能正确保存和加载
- 基础错误处理能正常工作

---

## Phase 2: Agent Alpha (智能代理核心)

### 目标
实现完整的 ReAct 循环，支持 AI 自主发送请求并迭代分析。

### 任务清单

#### 2.1 HTTP Client Manager
- [ ] 实现请求参数修改逻辑
  - [ ] URL 查询参数修改
  - [ ] POST Body 参数修改
  - [ ] Header 修改
  - [ ] Cookie 修改
- [ ] 实现请求发送功能（调用 Burp API）
- [ ] 实现响应捕获和数据清洗
  - [ ] 响应体截断（2KB）
  - [ ] Header 过滤
  - [ ] 二进制数据处理

**验收标准**: 能根据 LLM 的指令修改请求并发送，正确捕获响应。

#### 2.2 Agent Engine 核心
- [ ] 设计 ReAct 循环框架
- [ ] 实现迭代控制逻辑
  - [ ] 最大迭代次数限制
  - [ ] 提前终止条件判断
- [ ] 实现上下文管理
  - [ ] 保存历史对话记录
  - [ ] 构建 Observation 消息
- [ ] 实现 JSON 解析器
  - [ ] 验证 JSON Schema
  - [ ] 处理格式错误
  - [ ] 提取 Payload 和注入点

**验收标准**: 
- AI 能自主执行最多 N 次测试
- 每次测试的结果都能正确反馈给 AI
- 达到终止条件时能正确结束

#### 2.3 漏洞检测器 (核心类型)
- [ ] 实现 SQL Injection 检测器
  - [ ] System Prompt 优化
  - [ ] 常见 Payload 库
  - [ ] 响应特征识别
- [ ] 实现 XSS 检测器
- [ ] 实现 IDOR 检测器
- [ ] 定义 `VulnerabilityDetector` 接口

**验收标准**: 
- 针对已知漏洞靶场（如 DVWA），能成功检测出对应漏洞
- 误报率在可接受范围内

#### 2.4 思维链可视化
- [ ] 设计 ChatView 界面组件
- [ ] 实现消息气泡展示
  - [ ] AI Thought (绿色)
  - [ ] System Action (蓝色)
  - [ ] Observation (橙色)
  - [ ] Final Result (红色)
- [ ] 实现实时更新机制
- [ ] 支持滚动和搜索

**验收标准**: Dashboard 能实时展示 AI 的思考和行动过程。

#### 2.5 并发任务管理
- [ ] 实现 `TaskExecutor`
- [ ] 配置线程池（默认 1-3 并发）
- [ ] 实现任务队列
- [ ] 实现任务状态跟踪
- [ ] 实现任务取消功能

**验收标准**: 
- 能同时运行多个扫描任务
- Burp 主界面不会卡顿
- 能正确显示每个任务的状态

#### 2.6 扫描策略配置
- [ ] 创建 Scan Policy 配置面板
- [ ] 实现漏洞类型开关
  - [ ] SQL Injection
  - [ ] XSS
  - [ ] IDOR
  - [ ] SSRF
  - [ ] RCE (默认关闭)
- [ ] 实现 Agent 参数配置
  - [ ] Max Iterations (1-10)
  - [ ] Confidence Level (Low/Medium/High)

**验收标准**: 用户能自定义扫描行为，配置能正确生效。

### Phase 2 里程碑
- AI 能自主进行多轮测试
- 成功检测出至少 2 种漏洞类型（SQL 注入 + XSS）
- 思维链能完整展示在 Dashboard 中
- 支持并发扫描多个目标

---

## Phase 3: Scope & Polish (范围控制与优化)

### 目标
完善流量过滤逻辑，支持被动监听模式，提升用户体验。

### 任务清单

#### 3.1 Scope 配置
- [ ] 创建 Target & Scope 配置面板
- [ ] 实现 Scope Mode 切换
  - [ ] Use Burp Suite Scope
  - [ ] Custom Scope
- [ ] 实现 Host Filter
  - [ ] Include Hosts (支持通配符)
  - [ ] Exclude Hosts (黑名单)
- [ ] 实现 Extension Filter
  - [ ] 默认后缀黑名单
  - [ ] 自定义添加/删除

**验收标准**: 
- 只有符合 Scope 的请求才会被扫描
- 静态资源请求被正确过滤

#### 3.2 Proxy 被动监听
- [ ] 注册 `IHttpListener`
- [ ] 实现流量捕获逻辑
- [ ] 实现去重机制
  - [ ] URL + 参数哈希
  - [ ] 时间窗口控制（N 分钟内不重复）
- [ ] 实现后缀和 Host 过滤
- [ ] 将符合条件的请求放入任务队列

**验收标准**: 
- Proxy 拦截的流量能自动触发扫描
- 不会重复扫描相同请求
- 静态资源不会触发扫描

#### 3.3 Token 优化
- [ ] 实现响应体智能截断
  - [ ] HTML: 提取 body 内容
  - [ ] JSON: 保留完整结构
  - [ ] 二进制: 仅返回元数据
- [ ] 实现 Header 清洗
- [ ] 实现请求体压缩
- [ ] 添加 Token 使用统计

**验收标准**: 
- 单次对话 Token 消耗 < 8K
- 长响应能正确截断
- 不影响漏洞检测准确率

#### 3.4 错误处理增强
- [ ] 实现 LLM API 重试机制
- [ ] 实现 JSON 解析容错
- [ ] 实现详细的错误日志
- [ ] 实现用户友好的错误提示
- [ ] 实现异常任务自动恢复

**验收标准**: 
- API 临时故障不会导致任务失败
- 格式错误能给出明确提示
- 错误日志包含足够的调试信息

#### 3.5 性能优化
- [ ] 实现响应缓存（LRU）
- [ ] 实现批处理优化
- [ ] 优化线程池配置
- [ ] 减少 UI 刷新频率
- [ ] 实现懒加载（任务列表）

**验收标准**: 
- 长时间运行内存稳定
- UI 响应流畅
- 重复请求能利用缓存

#### 3.6 用户体验优化
- [ ] 添加加载动画
- [ ] 实现任务搜索和过滤
- [ ] 实现导出报告功能（JSON/HTML）
- [ ] 添加快捷键支持
- [ ] 优化配置界面布局
- [ ] 添加帮助文档链接

**验收标准**: 
- 界面美观易用
- 常用功能能快速访问
- 报告格式清晰完整

### Phase 3 里程碑
- 被动监听功能正常工作
- 过滤逻辑准确有效
- Token 消耗降低 30%+
- 用户体验显著提升

---

## Phase 4: Beta Release (测试与发布)

### 目标
完善测试，修复 Bug，准备公开发布。

### 任务清单

#### 4.1 测试
- [ ] 单元测试覆盖核心模块
- [ ] 集成测试（使用 DVWA、WebGoat）
- [ ] 性能测试
  - [ ] 并发压力测试
  - [ ] 内存泄漏检测
  - [ ] 长时间运行稳定性
- [ ] 兼容性测试
  - [ ] Burp Suite 不同版本
  - [ ] 不同操作系统
  - [ ] 不同 LLM 提供商

**验收标准**: 
- 核心功能测试通过率 100%
- 无严重 Bug
- 性能指标达标

#### 4.2 文档
- [ ] 用户手册
- [ ] 安装指南
- [ ] 配置示例
- [ ] 常见问题解答
- [ ] API 文档
- [ ] 贡献指南

**验收标准**: 新用户能根据文档独立完成安装和配置。

#### 4.3 安全审查
- [ ] API Key 存储安全性审查
- [ ] Payload 注入风险评估
- [ ] 隐私数据处理审查
- [ ] 代码安全扫描

**验收标准**: 无高危安全风险。

#### 4.4 发布准备
- [ ] 版本号确定（v1.0-beta）
- [ ] 发布说明编写
- [ ] GitHub Release 打包
- [ ] BApp Store 提交准备
- [ ] 演示视频制作

**验收标准**: 发布包可用，文档完整。

### Phase 4 里程碑
- Beta 版本发布
- 初步用户反馈收集
- 主要 Bug 已修复

---

## 未来规划 (Phase 5+)

### 高级功能
- [ ] 支持更多漏洞类型（XXE、CSRF、Deserialization）
- [ ] 支持自定义 Payload 库
- [ ] 支持自定义 Prompt 模板
- [ ] 支持插件式扩展（用户自定义检测器）

### 智能化增强
- [ ] 学习用户反馈，优化检测策略
- [ ] 支持链式漏洞组合检测
- [ ] 支持业务逻辑漏洞检测
- [ ] 集成漏洞数据库（CVE、OWASP）

### 协作功能
- [ ] 支持团队共享配置
- [ ] 支持多人协作扫描
- [ ] 集成 Jira/GitHub Issues
- [ ] 支持报告自动发送

### 性能提升
- [ ] 支持本地小模型（如 Llama 3）
- [ ] 实现模型微调
- [ ] 优化 Prompt 工程
- [ ] 实现智能 Token 管理

---

## 关键指标 (KPIs)

### 功能指标
- 漏洞检测准确率 > 80%
- 误报率 < 15%
- 支持漏洞类型 >= 5 种

### 性能指标
- 单次扫描平均耗时 < 2 分钟
- 单次对话 Token 消耗 < 8K
- 并发任务数 >= 3

### 用户体验
- 配置完成时间 < 5 分钟
- UI 响应延迟 < 100ms
- 文档完整度 >= 90%

---

## 风险与挑战

### 技术风险
- **LLM 输出不稳定**: 可能需要多次调试 Prompt
- **Burp API 限制**: 某些功能可能无法实现
- **Token 成本**: 大规模使用可能产生高额 API 费用

**缓解措施**: 
- 提供本地模型支持
- 优化 Prompt 和数据截断
- 实现缓存和批处理

### 产品风险
- **竞品压力**: 市场上可能出现类似产品
- **用户接受度**: 用户可能不信任 AI 的判断
- **合规问题**: 某些地区可能限制 AI 安全测试工具

**缓解措施**: 
- 强调 AI + 人类专家结合
- 提供详细的思维链展示
- 明确使用许可和责任声明

---

## 总结

本路线图预计总开发周期为 **8-12 周**，分阶段交付可用功能。各阶段相对独立，可根据实际情况调整优先级。

**下一步行动**: 启动 Phase 1 开发，完成 MVP 版本。
